# -*- coding: utf-8 -*-
"""ANL317 TMA ANALYTICS

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yR9B-63QrwaDqgU23epGmx7k0lpJOhpL
"""

#Loading the csv into colab
from google.colab import files
files.upload()

#Importing necessary libraries
import pandas as pd
from matplotlib import pyplot
import seaborn as sns
import numpy as np

#Loading the data from csv file to a df

dataS = pd.read_csv("ANL317 Data.csv", index_col = "DATE", header =0, sep=",")
dataS.head()

#Info
dataS.info()

#Plotting data to visualize seasonality
sns.lineplot(data=dataS)

#Differencing across the dataset
d_diff = dataS.diff(periods=1, axis=0)

#Visualizing the differenced dataset
sns.lineplot(data=d_diff)

#Adding the 3-period Moving Average
dataS['MA3'] = dataS.rolling(window=3).mean()

#Adding the 5 period Moving Average
dataS['MA5'] = dataS.rolling(window=5)['INCIDENTS'].mean()

#Adding the 7 period Moving Average
dataS['MA7'] = dataS.rolling(window=7)['INCIDENTS'].mean()

#Displaying the table
MAs = dataS.drop(['INCIDENTS'], axis=1)
MAs.head()

#Displaying the whole MA table
MAs.info

#Visualizing Data with New MAs
sns.lineplot(data=dataS)

del dataS['MA5']
del dataS['MA7']

"""DOUBLE EXPONENTIAL SMOOTHING MODEL;"""

#Getting necessary Libraries
from statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt

#Creating class
model = ExponentialSmoothing(dataS, trend='add',
                             damped=False, seasonal=None,
                             seasonal_periods = 1)
#Fitting the Model

#Fitting the model
model_fit = model.fit()
print(model_fit)

#Making Predictions
yhat = model_fit.forecast(30)
print(yhat)

#Plotting the new data with the old data
ax = dataS.plot( figsize = (6,4), legend = True)

yhat.plot(ax = ax)